{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashik-Ahammad/road-defect-detection-imageProcessing/blob/main/Image_processing_techniques_for_road_defect_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdfQvq6gNvye"
      },
      "source": [
        "Importing NumPy Library\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy4BM6aLINRH"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxJTLSKMO-H7"
      },
      "source": [
        "This cell creates the necessary directory for Kaggle API credentials, copies the kaggle.json file (which contains the API key), and sets the correct file permissions to ensure secure access to Kaggle datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD5jmSS5I4n0",
        "outputId": "18de3cf0-a2af-4820-f219-0b74fdfb11bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztL644-iJmt0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rSVhf8GQB_y"
      },
      "source": [
        "Downloading Pothole Detection Dataset from Kaggle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVD9yxe1J2Kf",
        "outputId": "ed1dce60-8148-4735-a487-5dd009c3b7d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/atulyakumar98/pothole-detection-dataset\n",
            "License(s): CC0-1.0\n",
            "pothole-detection-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download atulyakumar98/pothole-detection-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPyy2oMEQvvO"
      },
      "source": [
        "Extracting Pothole Detection Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MRP5QorUJ8Gn",
        "outputId": "a28e15a4-91cc-4870-8885-c6dfde9ffcdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/pothole-detection-dataset.zip\n",
            "replace /content/pathhole_dataset/normal/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/pothole-detection-dataset.zip -d /content/pathhole_dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdf15AV0KNK5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image_path = \"/content/pathhole_dataset/potholes/10.jpg\"  # Change this to your image path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Check if the image is loaded\n",
        "if image is not None:\n",
        "    print(\"Image Shape:\", image.shape)  # (Height, Width, Channels)\n",
        "else:\n",
        "    print(\"Error: Image not found or cannot be loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "86WTSdoEytVz"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def resize_image(input_image_path, output_image_path, size=(224, 224)):\n",
        "    original_image = Image.open(input_image_path).convert(\"RGB\")  # Convert to RGB\n",
        "    resized_image = original_image.resize(size)\n",
        "    resized_image.save(output_image_path, \"JPEG\")  # Ensure it's saved as JPEG\n",
        "\n",
        "def resize_images_in_directory(input_directory, output_directory):\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "    resize_compare_flag = True\n",
        "    for class_name in ['normal', 'potholes']:\n",
        "        input_folder = os.path.join(input_directory, class_name)\n",
        "        output_folder = os.path.join(output_directory, class_name)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "        for filename in os.listdir(input_folder):\n",
        "            input_image_path = os.path.join(input_folder, filename)\n",
        "            output_image_path = os.path.join(output_folder, os.path.splitext(filename)[0] + \".jpg\")  # Ensure JPG format\n",
        "\n",
        "            # Ensure the output directory exists\n",
        "            os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n",
        "\n",
        "            # Check if the file is an image (simple filter)\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
        "                print(f\"Resizing {input_image_path}...\")\n",
        "                resize_image(input_image_path, output_image_path)\n",
        "                if resize_compare_flag:\n",
        "                    compare_images(input_image_path, output_image_path)\n",
        "                    resize_compare_flag = False\n",
        "\n",
        "def compare_images(original_image_path, resized_image_path):\n",
        "    original_image = Image.open(original_image_path)\n",
        "    resized_image = Image.open(resized_image_path)\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(original_image)\n",
        "    ax[0].set_title(f'Original Image\\nDimensions: {original_image.size}')\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(resized_image)\n",
        "    ax[1].set_title(f'Resized Image\\nDimensions: {resized_image.size}')\n",
        "    ax[1].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Specify the paths\n",
        "input_directory = '/content/pathhole_dataset'\n",
        "output_directory = '/content/resize_dataset'\n",
        "\n",
        "# Resize images in the specified directories\n",
        "resize_images_in_directory(input_directory, output_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKmpGMdK0cFe"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def enhance_image(input_path, enhancement_type='contrast', level=1.2):\n",
        "    try:\n",
        "        img = Image.open(input_path)\n",
        "\n",
        "        # Ensure image is in a compatible format\n",
        "        if img.mode == 'RGBA':\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        if enhancement_type == 'contrast':\n",
        "            enhancer = ImageEnhance.Contrast(img)\n",
        "        elif enhancement_type == 'brightness':\n",
        "            enhancer = ImageEnhance.Brightness(img)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported enhancement type. Choose 'contrast' or 'brightness'.\")\n",
        "\n",
        "        # Enhance image\n",
        "        enhanced_img = enhancer.enhance(level)\n",
        "        return enhanced_img\n",
        "\n",
        "    except IOError:\n",
        "        print(\"Error opening or processing the image.\")\n",
        "        return None\n",
        "\n",
        "def save_image(image, output_path):\n",
        "    if image:\n",
        "        image.save(output_path, format='JPEG')\n",
        "\n",
        "def display_images(original_img, enhanced_img, title1='Original Image', title2='Enhanced Image'):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[0].set_title(title1)\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(enhanced_img)\n",
        "    axes[1].set_title(title2)\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def main(dataset_path, enhancement_type='contrast', level=1.2):\n",
        "    try:\n",
        "        # Select a random class directory\n",
        "        class_name = random.choice(os.listdir(dataset_path))\n",
        "        class_dir = os.path.join(dataset_path, class_name)\n",
        "\n",
        "        # Select a random image file\n",
        "        image_file = random.choice([f for f in os.listdir(class_dir) if f.endswith('.jpg') or f.endswith('.png')])\n",
        "        input_image_path = os.path.join(class_dir, image_file)\n",
        "\n",
        "        # Enhance the image\n",
        "        enhanced_img = enhance_image(input_image_path, enhancement_type, level)\n",
        "\n",
        "        # Load the original image\n",
        "        original_img = Image.open(input_image_path)\n",
        "\n",
        "        # Display both images\n",
        "        display_images(original_img, enhanced_img)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "dataset_path = \"/content/resize_dataset\"\n",
        "main(dataset_path, enhancement_type='contrast', level=1.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iioIlLS00sl"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "\n",
        "def enhance_and_save_image(input_path, output_path, level=1.2):\n",
        "    try:\n",
        "        img = Image.open(input_path)\n",
        "\n",
        "        # Convert image to RGB mode if it has an alpha channel\n",
        "        if img.mode == 'RGBA':\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        enhancer = ImageEnhance.Contrast(img)\n",
        "        enhanced_img = enhancer.enhance(level)\n",
        "\n",
        "        # Construct output filename with the contrast level\n",
        "        base, ext = os.path.splitext(output_path)\n",
        "        output_final_path = f\"{base}_contrast_{level}{ext}\"\n",
        "\n",
        "        enhanced_img.save(output_final_path)\n",
        "        print(f\"Enhanced image saved to: {output_final_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to enhance image {input_path}: {str(e)}\")\n",
        "\n",
        "def enhance_dataset_contrast(dataset_path, output_path):\n",
        "    for class_name in os.listdir(dataset_path):\n",
        "        class_dir = os.path.join(dataset_path, class_name)\n",
        "        output_class_dir = os.path.join(output_path, class_name)\n",
        "\n",
        "        if not os.path.exists(output_class_dir):\n",
        "            os.makedirs(output_class_dir)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.lower().endswith((\".jpg\", \".png\")):\n",
        "                input_image_path = os.path.join(class_dir, filename)\n",
        "                output_image_path = os.path.join(output_class_dir, filename)\n",
        "                enhance_and_save_image(input_image_path, output_image_path)\n",
        "\n",
        "# Usage example\n",
        "dataset_path = \"/content/resize_dataset\"\n",
        "output_path = \"/content/constrast_dataset\"\n",
        "enhance_dataset_contrast(dataset_path, output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_rwiSMG1GHr"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "def gamma_correction(input_image_path, output_image_path, gamma=1.0):\n",
        "    image = Image.open(input_image_path)\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "    gamma_corrected_image = image.point(lambda p: 255 * ((p / 255.0) ** gamma))\n",
        "\n",
        "    gamma_corrected_image.save(output_image_path)\n",
        "\n",
        "def apply_gamma_correction_in_directory(input_directory, output_directory, gamma=2.2):\n",
        "    comparison_done = True\n",
        "\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "    for subdir, dirs, files in os.walk(input_directory):\n",
        "        for file in files:\n",
        "            input_image_path = os.path.join(subdir, file)\n",
        "            relative_path = os.path.relpath(input_image_path, input_directory)\n",
        "            output_image_path = os.path.join(output_directory, relative_path)\n",
        "\n",
        "            os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n",
        "\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
        "                print(f\"Applying gamma correction to {input_image_path} with gamma={gamma}...\")\n",
        "                gamma_correction(input_image_path, output_image_path, gamma)\n",
        "                if comparison_done:\n",
        "                    compare_images(input_image_path, output_image_path)\n",
        "                    comparison_done = False\n",
        "\n",
        "def compare_images(original_image_path, processed_image_path):\n",
        "    original_image = Image.open(original_image_path)\n",
        "    processed_image = Image.open(processed_image_path)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    ax[0].imshow(original_image)\n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    ax[1].imshow(processed_image)\n",
        "    ax[1].set_title('Gamma Corrected Image')\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "input_directory = '/content/constrast_dataset'\n",
        "gamma_output_directory = '/content/gamma_correction'\n",
        "apply_gamma_correction_in_directory(input_directory, gamma_output_directory, gamma=1.3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1H16r1r1U9j"
      },
      "outputs": [],
      "source": [
        "import imgaug.augmenters as iaa\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage import io\n",
        "import random\n",
        "\n",
        "def augment_images_to_target(input_directory, output_directory, augmentation_pipeline, target_per_class=1500):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      input_directory: Directory containing the original images.\n",
        "      output_directory: Directory to save the augmented images.\n",
        "      augmentation_pipeline: Augmentation pipeline to apply to images.\n",
        "      target_per_class: Target number of images per class.\n",
        "    \"\"\"\n",
        "    for class_subdir in next(os.walk(input_directory))[1]:\n",
        "        class_dir_path = os.path.join(input_directory, class_subdir)\n",
        "        output_class_dir = os.path.join(output_directory, class_subdir)\n",
        "\n",
        "        if not os.path.exists(output_class_dir):\n",
        "            os.makedirs(output_class_dir)\n",
        "\n",
        "        image_files = [f for f in os.listdir(class_dir_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif'))]\n",
        "\n",
        "        total_images_needed = target_per_class - len(image_files)\n",
        "        if total_images_needed <= 0:\n",
        "            continue\n",
        "\n",
        "        # Randomly shuffle the image files\n",
        "        random.shuffle(image_files)\n",
        "\n",
        "        images_per_original = total_images_needed // len(image_files)\n",
        "\n",
        "        for file in image_files:\n",
        "            input_image_path = os.path.join(class_dir_path, file)\n",
        "            base_filename = os.path.splitext(file)[0]\n",
        "\n",
        "            image = io.imread(input_image_path)\n",
        "            image_augmented = []\n",
        "\n",
        "            for _ in range(images_per_original):\n",
        "                image_aug = augmentation_pipeline(image=image)\n",
        "                image_augmented.append(image_aug)\n",
        "\n",
        "            for idx, aug_image in enumerate(image_augmented, 1):\n",
        "                filename = f\"{base_filename}_augmented_{idx}.png\"\n",
        "                io.imsave(os.path.join(output_class_dir, filename), aug_image)\n",
        "\n",
        "        # Augment remaining images to meet the target\n",
        "        remaining_images_needed = target_per_class - len(os.listdir(output_class_dir))\n",
        "        for idx in range(remaining_images_needed):\n",
        "            file = random.choice(image_files)\n",
        "            input_image_path = os.path.join(class_dir_path, file)\n",
        "            base_filename = os.path.splitext(file)[0]\n",
        "\n",
        "            image = io.imread(input_image_path)\n",
        "            image_aug = augmentation_pipeline(image=image)\n",
        "            filename = f\"{base_filename}_augmented_extra_{idx}.png\"\n",
        "            io.imsave(os.path.join(output_class_dir, filename), image_aug)\n",
        "\n",
        "rotation_angles = [90, 180, 270]\n",
        "\n",
        "augmentation_pipeline = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Affine(rotate=random.choice(rotation_angles)),\n",
        "    iaa.Multiply((0.8, 1.2)),\n",
        "    iaa.LinearContrast((0.8, 1.2))\n",
        "])\n",
        "\n",
        "input_directory = '/content/gamma_correction'\n",
        "output_directory = '/content/Final_Augment_Image'\n",
        "\n",
        "augment_images_to_target(input_directory, output_directory, augmentation_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giUW0uC214ay"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "input_directory = '/content/pathhole_dataset'  # Update with your actual path\n",
        "augmented_directory = '/content/Final_Augment_Image'  # Update with your actual path where augmented images are saved\n",
        "\n",
        "def count_images_in_directory(directory):\n",
        "    counts = {}\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for dir_name in dirs:\n",
        "            dir_path = os.path.join(root, dir_name)\n",
        "            count = len([name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, name))])\n",
        "            counts[dir_name] = count\n",
        "    return counts\n",
        "\n",
        "# Count original and augmented images\n",
        "original_counts = count_images_in_directory(input_directory)\n",
        "augmented_counts = count_images_in_directory(augmented_directory)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(list(original_counts.items()), columns=['Class', 'Original Count'])\n",
        "df['Augmented Count'] = df['Class'].map(augmented_counts)\n",
        "\n",
        "# Display the DataFrame\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s_aBVi-2Acq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ensure that seaborn is styled to have a more appealing look\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Set the size of the figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the 'Original Count' and 'Augmented Count' for each class\n",
        "# Use a different color for each by specifying the 'palette' parameter\n",
        "sns.barplot(data=df.melt(id_vars='Class', value_vars=['Original Count', 'Augmented Count'], var_name='Type', value_name='Count'),\n",
        "            x='Class', y='Count', hue='Type', palette='viridis')\n",
        "\n",
        "# Add some helpful UI components\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate class labels for better readability\n",
        "plt.xlabel('Class')  # X-axis label\n",
        "plt.ylabel('Count')  # Y-axis label\n",
        "plt.title('Original vs Augmented Image Counts per Class')  # Title of the plot\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()  # Adjust the layout to make room for the rotated x-axis labels\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "110LusII2bKj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "def split_dataset(source_dir, train_dir, test_dir, val_dir, split_ratio=(0.8, 0.1, 0.1)):\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_dir = os.path.join(source_dir, class_name)\n",
        "        train_class_dir = os.path.join(train_dir, class_name)\n",
        "        test_class_dir = os.path.join(test_dir, class_name)\n",
        "        val_class_dir = os.path.join(val_dir, class_name)\n",
        "\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(test_class_dir, exist_ok=True)\n",
        "        os.makedirs(val_class_dir, exist_ok=True)\n",
        "\n",
        "        files = os.listdir(class_dir)\n",
        "        random.shuffle(files)\n",
        "\n",
        "        num_files = len(files)\n",
        "        train_split = int(num_files * split_ratio[0])\n",
        "        test_split = int(num_files * split_ratio[1])\n",
        "\n",
        "        train_files = files[:train_split]\n",
        "        test_files = files[train_split:train_split + test_split]\n",
        "        val_files = files[train_split + test_split:]\n",
        "\n",
        "        for file in tqdm(train_files, desc=f\"Copying {class_name} train files\"):\n",
        "            shutil.copy(os.path.join(class_dir, file), os.path.join(train_class_dir, file))\n",
        "\n",
        "        for file in tqdm(test_files, desc=f\"Copying {class_name} test files\"):\n",
        "            shutil.copy(os.path.join(class_dir, file), os.path.join(test_class_dir, file))\n",
        "\n",
        "        for file in tqdm(val_files, desc=f\"Copying {class_name} validation files\"):\n",
        "            shutil.copy(os.path.join(class_dir, file), os.path.join(val_class_dir, file))\n",
        "\n",
        "# Define paths\n",
        "source_dir = \"/content/Final_Augment_Image\"\n",
        "train_dir = \"/content/train\"\n",
        "test_dir = \"/content/test\"\n",
        "val_dir = \"/content/validation\"\n",
        "\n",
        "# Split dataset\n",
        "split_dataset(source_dir, train_dir, test_dir, val_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pvu787j2kRd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def evaluate_model_performance(model, history, test_generator):\n",
        "    # Plot Training and Validation Accuracy and Loss\n",
        "    def plot_training_history(history):\n",
        "        acc = history.history['accuracy']\n",
        "        val_acc = history.history['val_accuracy']\n",
        "        loss = history.history['loss']\n",
        "        val_loss = history.history['val_loss']\n",
        "        epochs = range(1, len(acc) + 1)\n",
        "\n",
        "        plt.figure(figsize=(14, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, acc, 'bo-', label='Training accuracy')\n",
        "        plt.plot(epochs, val_acc, 'ro-', label='Validation accuracy')\n",
        "        plt.title('Training and Validation Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, loss, 'bo-', label='Training loss')\n",
        "        plt.plot(epochs, val_loss, 'ro-', label='Validation loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Plot the overall confusion matrix\n",
        "    def plot_confusion_matrix(cm, class_names):\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.xlabel('Predicted labels')\n",
        "        plt.ylabel('True labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "    # Plot the confusion matrix for a specific class\n",
        "    def plot_class_confusion_matrix(cm, class_names, class_index):\n",
        "        class_cm = np.array([[cm[class_index, class_index], np.sum(cm[class_index, :]) - cm[class_index, class_index]],\n",
        "                             [np.sum(cm[:, class_index]) - cm[class_index, class_index], np.sum(cm) + cm[class_index, class_index] - np.sum(cm[class_index, :]) - np.sum(cm[:, class_index])]])\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        sns.heatmap(class_cm, annot=True, fmt='g', cmap='Blues', cbar=False,\n",
        "                    xticklabels=['True ' + class_names[class_index], 'False ' + class_names[class_index]],\n",
        "                    yticklabels=['True ' + class_names[class_index], 'False ' + class_names[class_index]])\n",
        "        plt.xlabel('Predicted labels')\n",
        "        plt.ylabel('True labels')\n",
        "        plt.title(f'Confusion Matrix for Class: {class_names[class_index]}')\n",
        "        plt.show()\n",
        "\n",
        "    # Plot misclassifications for each class\n",
        "    def plot_misclassifications(misclassifications, class_labels):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.bar(class_labels, misclassifications, color='red')\n",
        "        plt.xlabel('Class Labels')\n",
        "        plt.ylabel('Number of Misclassifications')\n",
        "        plt.title('Misclassifications for Each Class')\n",
        "        plt.xticks(rotation=45)  # Rotate class labels to improve readability\n",
        "        plt.tight_layout()  # Adjust subplots to give some padding\n",
        "        plt.show()\n",
        "\n",
        "    # Execute the plotting functions\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Prepare the test_generator and predict\n",
        "    test_generator.reset()\n",
        "    predictions = model.predict(test_generator)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = test_generator.classes\n",
        "    class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "    plot_confusion_matrix(conf_matrix, class_labels)\n",
        "\n",
        "    # Plot confusion matrix for each class\n",
        "    for idx, class_name in enumerate(class_labels):\n",
        "        plot_class_confusion_matrix(conf_matrix, class_labels, idx)\n",
        "\n",
        "    # Calculate and plot misclassifications\n",
        "    misclassifications = np.sum(conf_matrix, axis=1) - np.diag(conf_matrix)\n",
        "    plot_misclassifications(misclassifications, class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GAliQSD2s4s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def generate_classification_report(model, test_generator):\n",
        "    # Reset the test generator\n",
        "    test_generator.reset()\n",
        "\n",
        "    # Generate predictions from the model\n",
        "    predictions = model.predict(test_generator)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Retrieve the actual labels\n",
        "    true_classes = test_generator.classes\n",
        "\n",
        "    # Get class labels from the generator\n",
        "    class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "    # Generate the classification report\n",
        "    report = classification_report(true_classes, predicted_classes, target_names=class_labels, output_dict=True)\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "    # Remove unnecessary rows from the DataFrame\n",
        "    report_df.drop(index=['accuracy', 'macro avg', 'weighted avg'], inplace=True)\n",
        "\n",
        "    # Compute the confusion matrix\n",
        "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "    # Calculate specificities for each class\n",
        "    specificities = []\n",
        "    for i in range(len(class_labels)):\n",
        "        true_negatives = conf_matrix.sum() - conf_matrix[i,:].sum() - conf_matrix[:,i].sum() + conf_matrix[i,i]\n",
        "        false_positives = conf_matrix[:,i].sum() - conf_matrix[i,i]\n",
        "        spec = true_negatives / (true_negatives + false_positives)\n",
        "        specificities.append(spec)\n",
        "\n",
        "    # Add specificities to the report DataFrame\n",
        "    report_df['specificity'] = specificities\n",
        "\n",
        "    # Print or return the DataFrame\n",
        "    print(report_df)  # You could also return report_df if you want to use the DataFrame elsewhere\n",
        "\n",
        "# Usage example:\n",
        "# generate_classification_report(model, test_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2Oqw9VO2vmU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths for your dataset\n",
        "train_path = '/content/train'\n",
        "test_path = '/content/test'\n",
        "val_path = '/content/validation'\n",
        "modelsave_path = \"/content/MobileNetV2_model.h5\"\n",
        "\n",
        "# Define data generators\n",
        "batch_size = 32\n",
        "\n",
        "# Define and configure the data generator for training with data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Data generators for validation and testing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Load the testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Import MobileNetV2 model\n",
        "base_model = MobileNetV2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "# Build custom classification model on top of MobileNetV2\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Freeze pretrained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model\n",
        "checkpoint = ModelCheckpoint(\n",
        "    modelsave_path,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max'\n",
        ")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(\n",
        "    test_generator,\n",
        "    steps=test_generator.samples // batch_size\n",
        ")\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "# Save the final model\n",
        "model.save(modelsave_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iKbIg9OM_sC"
      },
      "outputs": [],
      "source": [
        "generate_classification_report(model, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoDTjjsBNBBg"
      },
      "outputs": [],
      "source": [
        "evaluate_model_performance(model, history, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYMu87mZ4HMY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths for your dataset\n",
        "train_path = '/content/train'\n",
        "test_path = '/content/test'\n",
        "val_path = '/content/validation'\n",
        "modelsave_path = \"/content/DenseNet201_model.h5\"\n",
        "\n",
        "# Define data generators\n",
        "batch_size = 32\n",
        "\n",
        "# Define and configure the data generator for training with data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Data generators for validation and testing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Load the testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Import DenseNet201 model\n",
        "base_model = DenseNet201(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "# Build custom classification model on top of DenseNet201\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Freeze pretrained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "checkpoint = ModelCheckpoint(\n",
        "    modelsave_path,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max'\n",
        ")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(\n",
        "    test_generator,\n",
        "    steps=test_generator.samples // batch_size\n",
        ")\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "# Save the final model\n",
        "model.save(modelsave_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPavvIxZNHK2"
      },
      "outputs": [],
      "source": [
        "generate_classification_report(model, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RIezpt0NJbZ"
      },
      "outputs": [],
      "source": [
        "evaluate_model_performance(model, history, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE1ipkxI6IuM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths for your dataset\n",
        "train_path = '/content/train'\n",
        "test_path = '/content/test'\n",
        "val_path = '/content/validation'\n",
        "modelsave_path = \"/content/Xception_model.h5\"\n",
        "\n",
        "# Define data generators\n",
        "batch_size = 32\n",
        "\n",
        "# Define and configure the data generator for training with data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Data generators for validation and testing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(299, 299),  # Xception requires input shape (299, 299)\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Load the testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Import Xception model\n",
        "base_model = Xception(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(299, 299, 3)\n",
        ")\n",
        "\n",
        "# Build custom classification model on top of Xception\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Freeze pretrained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "     optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "checkpoint = ModelCheckpoint(\n",
        "    modelsave_path,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max'\n",
        ")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(\n",
        "    test_generator,\n",
        "    steps=test_generator.samples // batch_size\n",
        ")\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "# Save the final model\n",
        "model.save(modelsave_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uJavfGCvNP0g"
      },
      "outputs": [],
      "source": [
        "generate_classification_report(model, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybBsZ_CRNSKx"
      },
      "outputs": [],
      "source": [
        "evaluate_model_performance(model, history, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33PQ9Grt_W_S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.applications import Xception, DenseNet201\n",
        "\n",
        "# Define paths for your dataset\n",
        "train_path = '/content/train'\n",
        "test_path = '/content/test'\n",
        "val_path = '/content/validation'\n",
        "modelsave_path = \"/content/hybrid_xception_dense.h5\"\n",
        "\n",
        "# Define data generators with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=24,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=24,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=24,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "# Define input tensor\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "\n",
        "# Load Xception and DenseNet201 models\n",
        "base_model_xception = Xception(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "base_model_densenet201 = DenseNet201(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "# Freeze the layers\n",
        "for layer in base_model_xception.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in base_model_densenet201.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Global average pooling and concatenate layers\n",
        "xception_output = GlobalAveragePooling2D()(base_model_xception.output)\n",
        "densenet201_output = GlobalAveragePooling2D()(base_model_densenet201.output)\n",
        "concatenated = Concatenate()([xception_output, densenet201_output])\n",
        "concatenated = BatchNormalization()(concatenated)\n",
        "\n",
        "# Dense layers\n",
        "x = Dense(1024, activation='relu')(concatenated)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Model compilation\n",
        "model = Model(inputs=input_tensor, outputs=predictions)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(modelsave_path, save_best_only=True, monitor='val_loss', mode='min')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Model training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[checkpoint, early_stop]\n",
        ")\n",
        "\n",
        "# Model evaluation\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_acc}, Test loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FedWw6QJNW2q"
      },
      "outputs": [],
      "source": [
        "generate_classification_report(model, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ldf9ZPt3NatZ"
      },
      "outputs": [],
      "source": [
        "evaluate_model_performance(model, history, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSsgLQik9j0M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "# Load the trained model\n",
        "model_path = \"/content/DenseNet201_model.h5\"   # Path to the saved model\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Define the image path\n",
        "img_path = \"/content/pathhole_dataset/potholes/10.jpg\"  # Path to your image\n",
        "\n",
        "# Define the dataset directory\n",
        "dataset_dir = \"/content/pathhole_dataset\"\n",
        "\n",
        "# Extract class labels from subdirectories within the dataset directory\n",
        "class_labels = sorted(os.listdir(dataset_dir))\n",
        "\n",
        "# Preprocess the image\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.\n",
        "\n",
        "# Make predictions using your model\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "confidence_score = np.max(predictions)\n",
        "predicted_class = class_labels[predicted_class_index]\n",
        "\n",
        "# Check for confusion between predicted class and dataset classes\n",
        "if predicted_class not in class_labels:\n",
        "    # Get predictions from ImageNet model\n",
        "    imagenet_predictions = decode_predictions(predictions, top=5)[0]\n",
        "\n",
        "    # Check if any of the ImageNet predictions match dataset classes\n",
        "    for label in imagenet_predictions:\n",
        "        if label[1] in class_labels:\n",
        "            predicted_class = label[1]\n",
        "            confidence_score = label[2]\n",
        "            break\n",
        "\n",
        "# Print the final predicted class and confidence score\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "print(\"Confidence score:\", confidence_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7AzU5-hF6CI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from google.colab.patches import cv2_imshow  # Use in Colab to display images\n",
        "\n",
        "# Load trained DenseNet201 model\n",
        "model_path = \"/content/DenseNet201_model.h5\"\n",
        "model = tf.keras.models.load_model(model_path, compile=False)  # Fix Warning\n",
        "\n",
        "# Define class labels\n",
        "class_labels = [\"Normal Road\", \"Path Hole\"]  # Adjust based on dataset classes\n",
        "\n",
        "# Upload your video\n",
        "video_path = \"/content/traveling whatsapp status, nature whatsapp status-tamil,travel status, nature status,status status.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define output video writer\n",
        "output_path = \"/content/detected_video2.avi\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # Exit loop if no frame\n",
        "\n",
        "    # Preprocess frame for model\n",
        "    img = cv2.resize(frame, (224, 224))  # Resize for DenseNet201\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "\n",
        "    # Predict class\n",
        "    predictions = model.predict(img)\n",
        "    class_index = np.argmax(predictions)\n",
        "    label = class_labels[class_index]\n",
        "    confidence = predictions[0][class_index] * 100\n",
        "\n",
        "    # Draw bounding box and label\n",
        "    color = (0, 255, 0) if label == \"Normal Road\" else (0, 0, 255)\n",
        "    cv2.rectangle(frame, (50, 50), (frame_width - 50, frame_height - 50), color, 3)\n",
        "    text = f\"{label}: {confidence:.2f}%\"\n",
        "    cv2.putText(frame, text, (60, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "\n",
        "    # Save processed frame to output video\n",
        "    out.write(frame)\n",
        "\n",
        "    # Show video frame in Colab\n",
        "    cv2_imshow(frame)  # Fixed for Colab\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\" Detection Complete! Download your video: {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRN3qUwYLLWkD92xuKMjFD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}